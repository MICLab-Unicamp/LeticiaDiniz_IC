{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a1fcea-e0b6-4eba-9406-67b48945fab0",
   "metadata": {},
   "source": [
    "## Estudo das características do ruído no espectrograma (abordagem inicial) - Geração de gráficos das métricas do espectrograma, histograma e espectro de transientes com ruído em função do nível de ruído adicionado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d4faa-b535-4c00-8463-01e8218a5b30",
   "metadata": {},
   "source": [
    "#### ATENÇÃO: FUNÇÃO DE GERAÇÃO DOS ESPECTROGRAMAS ESTÁ DESATUALIZADA COM RESPEITO A PRESENTE EM utils.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dbb70e-e0a6-450e-9354-857bb3bfcca4",
   "metadata": {},
   "source": [
    "### Definições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1833c7bf-fd0f-4f21-9d40-75530d69757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.signal import ShortTimeFFT\n",
    "from scipy.signal.windows import hann\n",
    "import random\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "import csv\n",
    "import datetime\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a36b406-a558-46c2-92d1-2bda69cecd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d39a65-8295-484b-94ae-3cb811b3201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "  # Add new data to CSV file\n",
    "    std = []\n",
    "    var = []\n",
    "    dict_metrics = {}\n",
    "    with open(file_path, mode='r', newline='') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in reader:\n",
    "            if line_count == 0:\n",
    "                head = (row[0].strip('][').split(', '))[2:]\n",
    "                aux = (row[1].strip('][').split(', '))\n",
    "                for i in range(0,len(head),2):\n",
    "                    dict_metrics[str(head[i][6:-1])] = {'mean':[],'std':[]}\n",
    "            else:\n",
    "                aux = (row[0].strip('][').split(', '))\n",
    "            aux2 = [float(i) for i in aux]\n",
    "            std.append(aux2[0])\n",
    "            var.append(aux2[1])\n",
    "            for i in range(0,len(head),2):\n",
    "                dict_metrics[str(head[i][6:-1])]['mean'].append(aux2[i+2])\n",
    "                dict_metrics[str(head[i][6:-1])]['std'].append(aux2[i+3])\n",
    "            line_count += 1\n",
    "            \n",
    "    return std,var,dict_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c7220-27e1-4f73-9b7f-a5c6c3ca4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spect_noise_estimation(spect, qntty, ppm):\n",
    "  std_array = np.empty(qntty)\n",
    "\n",
    "  for i in range(qntty):\n",
    "    idx_noise_1 = np.abs(ppm[i,:] - 8.5).argmin()\n",
    "    idx_noise_2 = np.abs(ppm[i,:] - 9.5).argmin()\n",
    "    idx_noise_3 = np.abs(ppm[i,:] - 10.5).argmin()\n",
    "\n",
    "    #assumes ppm is inverted: smaller values in higher indexes\n",
    "    ppm_array_1 = ppm[i,idx_noise_2:idx_noise_1]\n",
    "    ppm_array_2 = ppm[i,idx_noise_3:idx_noise_2]\n",
    "    spect_array_1 = np.real(spect[i,idx_noise_2:idx_noise_1])\n",
    "    spect_array_2 = np.real(spect[i,idx_noise_3:idx_noise_2])\n",
    "\n",
    "    estimate_1 = np.polyfit(ppm_array_1, spect_array_1, 2)\n",
    "    estimate_2 = np.polyfit(ppm_array_2, spect_array_2, 2)\n",
    "    aux_1 = (estimate_1[0]*(ppm_array_1**2)) + (estimate_1[1]*ppm_array_1) +  estimate_1[2]\n",
    "    aux_2 = (estimate_2[0]*(ppm_array_2**2)) + (estimate_2[1]*ppm_array_2) +  estimate_2[2]\n",
    "    detrending_1 = spect_array_1 - aux_1\n",
    "    detrending_2 = spect_array_2 - aux_2\n",
    "    std_1 = np.std(detrending_1)\n",
    "    std_2 = np.std(detrending_2)\n",
    "\n",
    "    if np.abs(std_1) < np.abs(std_2):\n",
    "      std = std_1\n",
    "    else:\n",
    "      std = std_2\n",
    "\n",
    "    std_array[i] = std\n",
    "\n",
    "  return std_array\n",
    "\n",
    "def spect_SNR_estimation(spect, qntty, ppm, ppm_min_peak,ppm_max_peak):\n",
    "\n",
    "  noise_array = spect_noise_estimation(spect, qntty, ppm)\n",
    "  SNR_array = np.empty(qntty)\n",
    "  peak_array = np.empty(qntty)\n",
    "\n",
    "  for i in range(qntty):\n",
    "    idx_GABA_0 = np.abs(ppm[i,:] - ppm_min_peak).argmin()\n",
    "    idx_GABA_1 = np.abs(ppm[i,:] - ppm_max_peak).argmin()\n",
    "    peak_amplitude = np.max(np.abs(np.real(spect[i,idx_GABA_1:idx_GABA_0])))\n",
    "\n",
    "    SNR = peak_amplitude/(2*noise_array[i])\n",
    "    SNR_array[i] = SNR\n",
    "    peak_array[i] = peak_amplitude\n",
    "\n",
    "  return SNR_array, noise_array, peak_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025a3c3-3225-4e15-8f05-cf16b3a4d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector_between_minus_one_and_one(complex_array):\n",
    "    real_parts = complex_array.real\n",
    "    imaginary_parts = complex_array.imag\n",
    "\n",
    "    min_real = np.min(real_parts)\n",
    "    max_real = np.max(real_parts)\n",
    "    min_imaginary = np.min(imaginary_parts)\n",
    "    max_imaginary = np.max(imaginary_parts)\n",
    "\n",
    "    range_real = max_real - min_real\n",
    "    range_imaginary = max_imaginary - min_imaginary\n",
    "\n",
    "    normalized_real = (((real_parts - min_real)/range_real)*2)-1\n",
    "    normalized_imaginary = (((imaginary_parts - min_imaginary)/range_imaginary)*2)-1\n",
    "\n",
    "    normalized_complex_array = normalized_real + 1j*normalized_imaginary\n",
    "    return normalized_complex_array\n",
    "\n",
    "def normalize_vector_min_max(complex_array):\n",
    "    real_parts = complex_array.real\n",
    "    imaginary_parts = complex_array.imag\n",
    "\n",
    "    min_real = np.min(real_parts)\n",
    "    max_real = np.max(real_parts)\n",
    "    min_imaginary = np.min(imaginary_parts)\n",
    "    max_imaginary = np.max(imaginary_parts)\n",
    "\n",
    "    range_real = max_real - min_real\n",
    "    range_imaginary = max_imaginary - min_imaginary\n",
    "\n",
    "    normalized_real = ((real_parts - min_real)/range_real)\n",
    "    normalized_imaginary = ((imaginary_parts - min_imaginary)/range_imaginary)\n",
    "\n",
    "    normalized_complex_array = normalized_real + 1j*normalized_imaginary\n",
    "    return normalized_complex_array\n",
    "\n",
    "def normalize_vector_zscore(complex_array):\n",
    "    real_parts = complex_array.real\n",
    "    imaginary_parts = complex_array.imag\n",
    "\n",
    "    mean_real = np.mean(real_parts)\n",
    "    std_real = np.std(real_parts)\n",
    "    mean_imaginary = np.mean(imaginary_parts)\n",
    "    std_imaginary = np.std(imaginary_parts)\n",
    "\n",
    "    normalized_real = (real_parts - mean_real)/std_real\n",
    "    normalized_imaginary = (imaginary_parts - mean_imaginary)/std_imaginary\n",
    "\n",
    "    normalized_complex_array = normalized_real + 1j*normalized_imaginary\n",
    "    return normalized_complex_array\n",
    "\n",
    "def get_normalized_spectrogram(fids,bandwidth,qntty,a,b,norm,correct_time):\n",
    "    w = hann(256, sym=True)\n",
    "    mfft_ = 446\n",
    "    SFT = ShortTimeFFT(w, hop=10, fs=bandwidth, mfft=mfft_, scale_to='magnitude', fft_mode = 'centered')\n",
    "    t_lo, t_hi, f_lo, f_hi = SFT.extent(fids.shape[1])\n",
    "    spgram = []\n",
    "    for i in range(qntty):\n",
    "        aux = SFT.stft(fids[i,:])\n",
    "        if norm == 'm1p1':\n",
    "            spgram.append(normalize_vector_between_minus_one_and_one(aux))\n",
    "        elif norm == 'zscore':\n",
    "            spgram.append(normalize_vector_zscore(aux))\n",
    "        elif norm == 'minmax':\n",
    "            spgram.append(normalize_vector_min_max(aux))\n",
    "        else:\n",
    "            spgram.append(aux/np.max(np.abs(aux)))\n",
    "    spgram = np.array(spgram)\n",
    "    \n",
    "    freq_spect = np.flip(np.linspace(f_lo,f_hi,mfft_))\n",
    "    ppm_spect = a*freq_spect+b\n",
    "    t_spect = np.linspace(t_lo,t_hi,spgram.shape[2])\n",
    "\n",
    "    if correct_time == True:\n",
    "        zero_idx = np.abs(t_spect - 0.0).argmin()\n",
    "        one_idx = np.abs(t_spect - 1.0).argmin()\n",
    "        t_spect = t_spect[zero_idx:one_idx]\n",
    "        spgram = spgram[:,:,zero_idx:one_idx]\n",
    "    \n",
    "    return spgram, freq_spect, ppm_spect, t_spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625a78c-86e2-4187-bf9b-f7856ac8f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_bins(bins):\n",
    "    mean_bins = []\n",
    "    for i in range(bins.shape[0]):\n",
    "        mean_bins.append([])\n",
    "        for j in range(bins.shape[1]-1):\n",
    "            aux = (bins[i,j+1]+bins[i,j])/2\n",
    "            mean_bins[i].append(aux)\n",
    "    mean_bins = np.array(mean_bins)\n",
    "    return mean_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ea9e2-5014-423e-9c62-1d58bdb2ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram(spgram,qntty):\n",
    "    \n",
    "    hist = []\n",
    "    bins_hist = []\n",
    "    for i in range(qntty):\n",
    "        #switched from 200 to 8000, from density to absolute\n",
    "        aux, bins = np.histogram(np.real(spgram[i,:,:]), 8000)\n",
    "        #added this normalization\n",
    "        aux = aux/aux.sum()\n",
    "        hist.append(aux)\n",
    "        bins_hist.append(bins)\n",
    "    hist = np.array(hist)\n",
    "    bins_hist = np.array(bins_hist)\n",
    "\n",
    "    bins_ = center_bins(bins_hist)\n",
    "    return hist, bins_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fb2d5-fb70-4552-bc6f-2a2bd5ab82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_TVs(spgram):\n",
    "  aux_delta_l = np.empty(spgram.shape)\n",
    "  for i in range(spgram.shape[1]-1):\n",
    "    aux = np.real(spgram[:,i+1,:]-spgram[:,i,:])\n",
    "    aux_delta_l[:,i,:]=aux\n",
    "  aux_delta_l[:,-1,:] = np.zeros((spgram.shape[0],spgram.shape[2]))\n",
    "  aux_delta_c = np.empty(spgram.shape)\n",
    "  for i in range(spgram.shape[2]-1):\n",
    "    aux = np.real(spgram[:,:,i+1]-spgram[:,:,i])\n",
    "    aux_delta_c[:,:,i]=aux\n",
    "  aux_delta_c[:,:,-1] = np.zeros((spgram.shape[0],spgram.shape[1]))\n",
    "  TV_aniso = np.sum(np.abs(aux_delta_l)+np.abs(aux_delta_c), axis =(1,2))\n",
    "  TV_iso = np.sum(np.sqrt((np.abs(aux_delta_l)**2)+(np.abs(aux_delta_c)**2)), axis=(1,2))\n",
    "\n",
    "  return TV_aniso, TV_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5870a1-29c6-4d3b-add2-4dcee51b45ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(seq_stats,names):\n",
    "\n",
    "  metrics = {}\n",
    "  for i,value in enumerate(seq_stats):\n",
    "    metrics[names[i]] = {}\n",
    "    metrics[names[i]]['mean'] = np.mean(value)\n",
    "    metrics[names[i]]['std'] = np.std(value)\n",
    "\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac473714-7f39-4155-9f92-94c7060532b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram_metrics(hist,bins):\n",
    "    #no median, no range, no cov, new skew (corrected), new kurt (corrected), added max, added LWHM\n",
    "    argmax_hist = np.argmax(hist,axis=1)\n",
    "    mode_ = []\n",
    "    for i in range(argmax_hist.shape[0]):\n",
    "        mode_.append(bins[i,argmax_hist[i]]) #pixel value that happens the most\n",
    "    mode_ = np.array(mode_)\n",
    "    max_ = np.max(hist,axis=1) #peak amplitude\n",
    "\n",
    "    LWHM_ = []\n",
    "    value_ref_larg = 1e-4\n",
    "    for i in range(hist.shape[0]):\n",
    "        aux_ans_min = 10000000\n",
    "        aux_idx_min = 0\n",
    "        aux_ans_max= 10000000\n",
    "        aux_idx_max = 0\n",
    "        for j in range(argmax_hist[i]):\n",
    "            if np.abs(hist[i,j] - value_ref_larg) < aux_ans_min:\n",
    "                aux_ans_min = np.abs(hist[i,j] - value_ref_larg)\n",
    "                aux_idx_min = j\n",
    "        for j in range(argmax_hist[i],hist.shape[1]):\n",
    "            if np.abs(hist[i,j] - value_ref_larg) < aux_ans_max:\n",
    "                aux_ans_max = np.abs(hist[i,j] - value_ref_larg)\n",
    "                aux_idx_max = j\n",
    "        LWHM_.append(np.abs(bins[i,aux_idx_max]-bins[i,aux_idx_min]))\n",
    "    LWHM_ = np.array(LWHM_) #linewidth\n",
    "\n",
    "    \n",
    "    mean_ = np.sum(bins*hist,axis=1)\n",
    "    std_ = np.sqrt(np.sum(((bins - mean_[:, np.newaxis])**2)*hist,axis=1))\n",
    "    skewness_ = np.sum(((bins - mean_[:, np.newaxis])/std_[:, np.newaxis])**3*hist,axis=1)\n",
    "    kurtosis_ = np.sum(((bins - mean_[:, np.newaxis])/std_[:, np.newaxis])**4*hist,axis=1)\n",
    "    \n",
    "    names = ['mode','max','width','skewness','kurtosis']\n",
    "    seq_stats = (mode_,max_,LWHM_,skewness_,kurtosis_)\n",
    "    metrics = stats(seq_stats,names)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ab82b-b0b9-4a7b-9452-13156f8e1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spgram_metrics(spgram,time,ppm):\n",
    "  mean_ = np.mean(np.real(spgram),axis = (1,2))\n",
    "  median_ = np.median(np.real(spgram),axis = (1,2))\n",
    "  std_ = np.std(np.real(spgram),axis = (1,2))\n",
    "  trace_ = []\n",
    "  for i in range(spgram.shape[0]):\n",
    "    trace_.append(np.trace(np.cov(np.real(spgram[i,:,:]))))\n",
    "  trace_ = np.array(trace_)\n",
    "  TV_aniso,TV_iso = calculate_TVs(spgram)\n",
    "\n",
    "  idx_time_1 = np.abs(time - 0.4).argmin()\n",
    "  idx_time_2 = np.abs(time - 0.6).argmin()\n",
    "  idx_freq_1 = np.abs(np.flip(ppm) - 1).argmin()\n",
    "  idx_freq_2 = np.abs(np.flip(ppm) - 8).argmin()\n",
    "  sum_late = np.sum(np.abs(np.real(spgram[:,:,idx_time_2:])),axis=(1,2))\n",
    "  #changed mean late and std late || before np.mean(np.abs(np.real(\n",
    "  mean_late = np.mean(np.real(spgram[:,:,idx_time_2:]),axis=(1,2))\n",
    "  std_late = np.std(np.real(spgram[:,:,idx_time_2:]),axis=(1,2))\n",
    "  TV_aniso_late,TV_iso_late = calculate_TVs(spgram[:,idx_freq_1:idx_freq_2,idx_time_2:])\n",
    "  #changed mean main and std main || before np.mean(np.abs(np.real(\n",
    "  mean_main_sig = np.mean(np.real(spgram[:,idx_freq_1:idx_freq_2,:idx_time_1]),axis=(1,2))\n",
    "  std_main_sig = np.std(np.real(spgram[:,idx_freq_1:idx_freq_2,:idx_time_1]),axis=(1,2))\n",
    "  TV_aniso_main_sig,TV_iso_main_sig = calculate_TVs(spgram[:,idx_freq_1:idx_freq_2,:idx_time_1])\n",
    "\n",
    "  names = ['MEAN_total','median_total','STD_total','trace_total','TV_aniso_total','TV_iso_total',\n",
    "           'sum_late','MEAN_late','STD_late','TV_aniso_late','TV_iso_late',\n",
    "           'MEAN_main_sig','STD_main_sig','TV_aniso_main_sig','TV_iso_main_sig']\n",
    "  seq_stats = (mean_,median_,std_,trace_,TV_aniso,TV_iso,\n",
    "               sum_late,mean_late,std_late,TV_aniso_late,TV_iso_late,\n",
    "               mean_main_sig,std_main_sig,TV_aniso_main_sig,TV_iso_main_sig)\n",
    "  metrics = stats(seq_stats,names)\n",
    "\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279441cd-7bad-4376-90f5-642b1e7fa878",
   "metadata": {},
   "source": [
    "### Extrai dados dos arquivos com as métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde88604-da58-4bbe-a6d8-c01e45b235af",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gt_file = '../sample_data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d98fb-4400-45ad-91d3-3450e7541e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qntty = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38955f77-0b1c-40a2-9917-32113cd69162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data obtained on EditedMRS_Reconstruction_Challenge github -- Ground-truths\n",
    "with h5py.File(path_gt_file) as hf:\n",
    "  print(hf.keys())\n",
    "  gt_fids = hf[\"ground_truth_fids\"][()][:qntty]\n",
    "  ppm = hf[\"ppm\"][()][:qntty]\n",
    "  t = hf[\"t\"][()][:qntty]\n",
    "  print(gt_fids.shape)\n",
    "  print(ppm.shape)\n",
    "  print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8213f962-45a9-4b96-95ad-a6d7beb8108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_spectrum_path = 'data_Real_Norm_ABS_STFT_FID_spectrum_timecorrected.csv'\n",
    "file_hist_path = 'data_Real_Norm_ABS_STFT_FID_hist_timecorrected.csv' \n",
    "file_spgram_path = 'data_Real_Norm_ABS_STFT_FID_spgram_timecorrected.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df6cb4-b06d-4b26-9259-0f076148867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_list_to_array(dict_data):\n",
    "    keys = list(dict_data.keys())\n",
    "    for key in keys:\n",
    "        aux1 = np.array(dict_data[key]['mean'])\n",
    "        aux2 = np.array(dict_data[key]['std'])\n",
    "        dict_data[key]['mean'] = aux1\n",
    "        dict_data[key]['std'] = aux2\n",
    "\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f3260-468e-4284-8f64-8a980589364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "std,var, metrics_spectrum_corrupted_avgs = read_data(file_spectrum_path)\n",
    "std,var, metrics_hist_corrupted_avgs = read_data(file_hist_path)\n",
    "std,var, metrics_spgram_corrupted_avgs = read_data(file_spgram_path)\n",
    "metrics_spectrum_corrupted_avgs = from_list_to_array(metrics_spectrum_corrupted_avgs)\n",
    "metrics_hist_corrupted_avgs = from_list_to_array(metrics_hist_corrupted_avgs)\n",
    "metrics_spgram_corrupted_avgs = from_list_to_array(metrics_spgram_corrupted_avgs)\n",
    "std = np.array(std)\n",
    "var = np.array(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9809b2b-615f-4309-ae80-3958cd948784",
   "metadata": {},
   "source": [
    "### Gera métricas de dados sem ruído para comparação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0061a2-4e79-4fc5-bdbf-8f1fd3d3413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "dwelltime = t[0,1]-t[0,0]\n",
    "bandwidth = 1/dwelltime\n",
    "N = gt_fids.shape[1]\n",
    "\n",
    "#gts\n",
    "spectra_gt_fids = np.fft.fftshift(np.fft.ifft(gt_fids,n=N,axis = 1), axes = 1)\n",
    "spectra_gt_diff = spectra_gt_fids[:,:,1] - spectra_gt_fids[:,:,0]\n",
    "freq = np.flip(np.fft.fftshift(np.fft.fftfreq(N, d = dwelltime)))\n",
    "\n",
    "#to get ppm axis\n",
    "idx_min = np.real(spectra_gt_diff[0,:]).argmin()\n",
    "idx_max = np.real(spectra_gt_diff[0,:]).argmax()\n",
    "#p = a*f + b\n",
    "a = (ppm[0,idx_max] - ppm[0,idx_min])/(freq[idx_max]-freq[idx_min])\n",
    "b = ppm[0,idx_max] - a*freq[idx_max]\n",
    "\n",
    "names_stats_spectrum = ['SNR','STD','peak']\n",
    "names_stats_hist = ['mode','max','width','skewness','kurtosis']\n",
    "names_stats_spgram = ['MEAN_total','median_total','STD_total','trace_total','TV_aniso_total','TV_iso_total',\n",
    "           'sum_late','MEAN_late','STD_late','TV_aniso_late','TV_iso_late',\n",
    "           'MEAN_main_sig','STD_main_sig','TV_aniso_main_sig','TV_iso_main_sig']\n",
    "\n",
    "SNR_gt, std_gt, peak_gt = spect_SNR_estimation(spectra_gt_diff, qntty, ppm, 2.79, 3.55)\n",
    "metrics_spectrum_gt = stats((SNR_gt, std_gt, peak_gt),names_stats_spectrum)\n",
    "\n",
    "gt_fids_diff = gt_fids[:,:,1]-gt_fids[:,:,0]\n",
    "spgram_gt, freq_spect, ppm_spect, t_spect = get_normalized_spectrogram(gt_fids_diff,bandwidth,qntty,a,b,'abs',True)\n",
    "metrics_spgram_gt = get_spgram_metrics(spgram_gt,t_spect,ppm_spect)\n",
    "\n",
    "hist_gt, bins_hist = get_histogram(spgram_gt,qntty)\n",
    "metrics_hist_gt = get_histogram_metrics(hist_gt,bins_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772627a4-f25d-4551-b775-3fa4fbc9a01a",
   "metadata": {},
   "source": [
    "### Gráficos métricas do espectro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94489878-4c32-4ba2-8930-fb6bb6e555ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = np.arange(std.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ef2ec5-e131-4160-97cb-259b6f4096ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(20,4))\n",
    "\n",
    "ax[0].plot(std,color='blue', label = 'STD added to transients')\n",
    "ax[0].fill_between(test_idx, std - var, std + var, alpha=0.35, color = 'blue')\n",
    "ax[0].plot(metrics_spectrum_corrupted_avgs['STD']['mean']*420,color='red', label = 'STD*420 measured in avg')\n",
    "ax[0].fill_between(test_idx, metrics_spectrum_corrupted_avgs['STD']['mean']*420 - metrics_spectrum_corrupted_avgs['STD']['std']*420, \n",
    "                   metrics_spectrum_corrupted_avgs['STD']['mean']*420 + metrics_spectrum_corrupted_avgs['STD']['std']*420, alpha=0.35, color = 'red')\n",
    "ax[0].legend(loc='upper left')\n",
    "\n",
    "ax[1].plot(std,metrics_spectrum_corrupted_avgs['SNR']['mean'],color='red', label = 'SNR measured in avg')\n",
    "ax[1].fill_between(std, metrics_spectrum_corrupted_avgs['SNR']['mean'] - metrics_spectrum_corrupted_avgs['SNR']['std'], \n",
    "                   metrics_spectrum_corrupted_avgs['SNR']['mean'] + metrics_spectrum_corrupted_avgs['SNR']['std'], alpha=0.35, color = 'red')\n",
    "ax[1].legend(loc='upper left')\n",
    "\n",
    "\n",
    "ax[2].plot(std,metrics_spectrum_corrupted_avgs['peak']['mean'],color='red', label = 'peak measured in avg')\n",
    "ax[2].fill_between(std, metrics_spectrum_corrupted_avgs['peak']['mean'] - metrics_spectrum_corrupted_avgs['peak']['std'], \n",
    "                   metrics_spectrum_corrupted_avgs['peak']['mean'] + metrics_spectrum_corrupted_avgs['peak']['std'], alpha=0.35, color = 'red')\n",
    "ax[2].hlines(metrics_spectrum_gt['peak']['mean'],std[0],std[-1],color='c',label='GT level')\n",
    "ax[2].fill_between(std, metrics_spectrum_gt['peak']['mean'] - metrics_spectrum_gt['peak']['std'], \n",
    "                   metrics_spectrum_gt['peak']['mean'] + metrics_spectrum_gt['peak']['std'], alpha=0.35, color = 'c')\n",
    "ax[2].legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf982aa0-888f-409b-8bbd-a7e8e0258a74",
   "metadata": {},
   "source": [
    "### Gráficos métricas do histograma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58043519-e509-461a-b108-00bb2ff244b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3,figsize=(20,8))\n",
    "\n",
    "for i in range(len(names_stats_hist)):\n",
    "    ax.flat[i].plot(std,metrics_hist_corrupted_avgs[names_stats_hist[i]]['mean'],color='red', label = names_stats_hist[i]+' measured in avg')\n",
    "    ax.flat[i].fill_between(std, metrics_hist_corrupted_avgs[names_stats_hist[i]]['mean'] - metrics_hist_corrupted_avgs[names_stats_hist[i]]['std'], \n",
    "                       metrics_hist_corrupted_avgs[names_stats_hist[i]]['mean'] + metrics_hist_corrupted_avgs[names_stats_hist[i]]['std'], alpha=0.35, color = 'red')\n",
    "    ax.flat[i].hlines(metrics_hist_gt[names_stats_hist[i]]['mean'],std[0],std[-1],color='c',label='GT level')\n",
    "    ax.flat[i].fill_between(std, metrics_hist_gt[names_stats_hist[i]]['mean'] - metrics_hist_gt[names_stats_hist[i]]['std'], \n",
    "                       metrics_hist_gt[names_stats_hist[i]]['mean'] + metrics_hist_gt[names_stats_hist[i]]['std'], alpha=0.35, color = 'c')\n",
    "    ax.flat[i].legend(loc='upper left')\n",
    "\n",
    "ax[1,2].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5cd08e-26c6-4c4e-92e6-d09ae7b448e6",
   "metadata": {},
   "source": [
    "### Gráficos métricas do espectrograma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f147a92-4153-4b32-af84-d89cf828e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,3,figsize=(20,20))\n",
    "\n",
    "for i in range(len(names_stats_spgram)):\n",
    "    ax.flat[i].plot(std,metrics_spgram_corrupted_avgs[names_stats_spgram[i]]['mean'],color='red', label = names_stats_spgram[i]+' measured in avg')\n",
    "    ax.flat[i].fill_between(std, metrics_spgram_corrupted_avgs[names_stats_spgram[i]]['mean'] - metrics_spgram_corrupted_avgs[names_stats_spgram[i]]['std'], \n",
    "                       metrics_spgram_corrupted_avgs[names_stats_spgram[i]]['mean'] + metrics_spgram_corrupted_avgs[names_stats_spgram[i]]['std'], alpha=0.35, color = 'red')\n",
    "    ax.flat[i].hlines(metrics_spgram_gt[names_stats_spgram[i]]['mean'],std[0],std[-1],color='c',label='GT level')\n",
    "    ax.flat[i].fill_between(std, metrics_spgram_gt[names_stats_spgram[i]]['mean'] - metrics_spgram_gt[names_stats_spgram[i]]['std'], \n",
    "                       metrics_spgram_gt[names_stats_spgram[i]]['mean'] + metrics_spgram_gt[names_stats_spgram[i]]['std'], alpha=0.35, color = 'c')\n",
    "    ax.flat[i].legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e043a-f476-493e-9ff9-c34b272a891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(15,4))\n",
    "\n",
    "names_aux = ['TV_aniso_total','STD_late','TV_aniso_late']\n",
    "\n",
    "for i in range(len(names_aux)):\n",
    "    ax.flat[i].plot(std,metrics_spgram_corrupted_avgs[names_aux[i]]['mean'],color='red', label = names_aux[i]+' measured in avg')\n",
    "    ax.flat[i].fill_between(std, metrics_spgram_corrupted_avgs[names_aux[i]]['mean'] - metrics_spgram_corrupted_avgs[names_aux[i]]['std'], \n",
    "                       metrics_spgram_corrupted_avgs[names_aux[i]]['mean'] + metrics_spgram_corrupted_avgs[names_aux[i]]['std'], alpha=0.35, color = 'red')\n",
    "    ax.flat[i].hlines(metrics_spgram_gt[names_aux[i]]['mean'],std[0],std[-1],color='c',label='GT level')\n",
    "    ax.flat[i].fill_between(std, metrics_spgram_gt[names_aux[i]]['mean'] - metrics_spgram_gt[names_aux[i]]['std'], \n",
    "                       metrics_spgram_gt[names_aux[i]]['mean'] + metrics_spgram_gt[names_aux[i]]['std'], alpha=0.35, color = 'c')\n",
    "    ax.flat[i].legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed03f3f-66cb-44d5-98a7-477ff6f96387",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(std,metrics_spectrum_corrupted_avgs['STD']['mean'],color='red', label = 'STD measured in Spectrum')\n",
    "plt.fill_between(std, metrics_spectrum_corrupted_avgs['STD']['mean'] - metrics_spectrum_corrupted_avgs['STD']['std'], \n",
    "                   metrics_spectrum_corrupted_avgs['STD']['mean'] + metrics_spectrum_corrupted_avgs['STD']['std'], alpha=0.35, color = 'red')\n",
    "\n",
    "names_aux = ['STD_total','STD_late','STD_main_sig','trace_total']\n",
    "color_aux = ['g','y','grey','c']\n",
    "for i in range(len(names_aux)):\n",
    "    plt.plot(std,metrics_spgram_corrupted_avgs[names_aux[i]]['mean'],color=color_aux[i], label = names_aux[i]+' measured in avg')\n",
    "    plt.fill_between(std, metrics_spgram_corrupted_avgs[names_aux[i]]['mean'] - metrics_spgram_corrupted_avgs[names_aux[i]]['std'], \n",
    "                       metrics_spgram_corrupted_avgs[names_aux[i]]['mean'] + metrics_spgram_corrupted_avgs[names_aux[i]]['std'], alpha=0.35, color = color_aux[i])\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a078f-a4a4-40ee-931f-abf812ef6b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(std,metrics_spectrum_corrupted_avgs['STD']['mean'],color='red', label = 'STD measured in Spectrum')\n",
    "plt.fill_between(std, metrics_spectrum_corrupted_avgs['STD']['mean'] - metrics_spectrum_corrupted_avgs['STD']['std'], \n",
    "                   metrics_spectrum_corrupted_avgs['STD']['mean'] + metrics_spectrum_corrupted_avgs['STD']['std'], alpha=0.35, color = 'red')\n",
    "names_aux =  ['TV_aniso_total','TV_aniso_late','TV_aniso_main_sig']\n",
    "#names_aux =  ['TV_iso_total','TV_iso_late','TV_iso_main_sig']\n",
    "color_aux = ['g','y','grey']\n",
    "for i in range(len(names_aux)):\n",
    "    plt.plot(std,metrics_spgram_corrupted_avgs[names_aux[i]]['mean'],color=color_aux[i], label = names_aux[i]+' measured in avg')\n",
    "    plt.fill_between(std, metrics_spgram_corrupted_avgs[names_aux[i]]['mean'] - metrics_spgram_corrupted_avgs[names_aux[i]]['std'], \n",
    "                       metrics_spgram_corrupted_avgs[names_aux[i]]['mean'] + metrics_spgram_corrupted_avgs[names_aux[i]]['std'], alpha=0.35, color = color_aux[i])\n",
    "plt.legend(loc='center right')\n",
    "plt.yscale('log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
